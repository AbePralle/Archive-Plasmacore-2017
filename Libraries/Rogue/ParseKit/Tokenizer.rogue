module ParseKit<<$ParserType>>

class Tokenizer
  GLOBAL PROPERTIES
    token_types           = StringTable<<Int32>>()
    descriptions          = String[]
    symbols               = String[]
    structural_flags      = Logical[]
    keywords              = StringTable<<Int32>>()
    rules                 = Table<<Character,ScanRule>>()
    fn_consume_whitespace : Function(Tokenizer)
    fn_identifier         : Function(Tokenizer,String)
    fn_integer            : Function(Tokenizer,Int64)
    fn_real               : Function(Tokenizer,Real64)

  GLOBAL METHODS
    method define( symbol:String, description=null:String, &is_keyword, &is_structural )
      local type = token_type( symbol )
      descriptions[ type ] = select{ description || symbol }
      structural_flags[ type ] = is_structural
      if (is_keyword)
        keywords[ symbol ] = type
      else
        local handler : ScanRule
        if (symbol.count > 1) handler = ScanRule( symbol, type )
        else                  handler = ScanSingleCharacter( symbol, type )
        on( symbol, handler )
      endIf

    method description( token_type:Int32 )->String
      return descriptions[ token_type % descriptions.count ]

    method on( symbol:String, rule:ScanRule )
      local ch = symbol[0]
      if (rules.contains(ch))
        rules[ ch ] = rules[ch].insert( rule )
      else
        rules[ ch ] = rule
      endIf

    method on( symbol:String, handler:Function(Tokenizer)->Logical )
      if (symbol.count == 1)
        on( symbol, ScanSingleCharacter(symbol,handler) )
      else
        on( symbol, ScanRule(symbol,handler) )
      endIf

    method on_consume_whitespace( fn:Function(Tokenizer) )
      Tokenizer.fn_consume_whitespace = fn

    method on_identifier( fn:Function(Tokenizer,String) )
      Tokenizer.fn_identifier = fn

    method on_integer( fn:Function(Tokenizer,Int64) )
      Tokenizer.fn_integer = fn

    method on_real( fn:Function(Tokenizer,Real64) )
      Tokenizer.fn_real = fn

    method stringify( t:Token )->String
      return symbol( t.type )

    method symbol( token_type:Int32 )->String
      return symbols[ token_type % symbols.count ]

    method token_type( symbol:String )->Int32
      local entry = token_types.find( symbol )
      if (entry) return entry.value

      local type = token_types.count
      token_types[ symbol ] = type
      symbols.add( symbol )
      descriptions.add( symbol )
      structural_flags.add( false )

      return type

  PROPERTIES
    filepath       : String
    scanner        : Scanner
    tokens         : Token[]
    spaces_per_tab = 2
    buffer         = StringBuilder()
    type_eol       = token_type( "\n" ) : Int32

  METHODS
    method init

    method consume( ch:Character )->Logical [macro]
      this.scanner.consume( ch )

    method consume( text:String )->Logical [macro]
      this.scanner.consume( text )

    method consume_eols->Logical
      local found_any = false
      while (consume('\n')) found_any = true
      return found_any

    method consume_spaces->Logical
      local found_any = false
      while (consume(' ')) found_any = true
      return found_any

    method consume_whitespace->Logical
      local found_any = false
      while (consume_spaces or consume_eols) found_any = true
      return true

    method has_another->Logical [macro]
      this.scanner.has_another

    method is_id_start( ch:Character )->Logical
      return (ch.is_letter or ch == '_')

    method is_id_continuation( ch:Character )->Logical
      return (ch.is_letter or ch == '_' or ch.is_number)

    method peek->Character [macro]
      this.scanner.peek

    method read->Character [macro]
      this.scanner.read

    method scan_number_string->String
      buffer.clear
      while (peek.is_number) buffer.print( read )
      if (consume('.'))
        buffer.print( '.' )
        while (peek.is_number) buffer.print( read )
      endIf
      if (consume('e') or consume('E'))
        buffer.print( 'e' )
        if (consume('-'))   buffer.print( '-' )
        else consume( '+' ) buffer.print( '+' )
        while (peek.is_number) buffer.print( read )
      endIf
      return buffer->String.to_lowercase

    method tokenize( filepath )->Token[]
      scanner = Scanner( File(filepath), &=spaces_per_tab )
      return tokenize

    method tokenize( filepath, source:String )->Token[]
      scanner = Scanner( source, &=spaces_per_tab )
      return tokenize

    method tokenize( filepath, source:Character[] )->Token[]
      scanner = Scanner( source, &=spaces_per_tab )
      return tokenize

    method tokenize->Token[]
      tokens = Token[]
      while (tokenize_another) noAction
      tokens.add( Token(type_eol) )
      return tokens

    method tokenize_another->Logical
      Token.next_filepath = filepath
      Token.next_line = scanner.line
      Token.next_column = scanner.column

      if (fn_consume_whitespace) fn_consume_whitespace( this )
      else                       consume_whitespace

      if (not has_another) return false

      if (consume('\n')) tokens.add( Token(type_eol) ); return true

      local _rules = rules[ peek ]
      if (_rules)
        if (_rules(this)) return true
      endIf

      if (tokenize_comment)    return true
      if (tokenize_number)     return true
      if (tokenize_identifier) return true

      throw ParseError( filepath, scanner.line, "Syntax error: unexpected '$'." (peek) )

    method tokenize_comment->Logical
      local text = scan_comment
      if (not text) return false

      if (tokens.count and tokens.last.type == type_eol)
        if (not tokens.last.text) tokens.last.text = text
        else                      tokens.last.text += text
      endIf
      return true

    method tokenize_identifier->Logical
      local text = scan_identifier
      if (not text) return false

      local entry = keywords.find( text )
      if (entry)
        local type = entry.value
        tokens.add( Token(type) )
      else
        if (fn_identifier) fn_identifier( this, text )
      endIf

      return true

    method tokenize_number->Logical
      if (not peek.is_number) return false

      local base = 10
      if (consume("0b"))     base = 2
      if (consume("0c"))     base = 8
      elseIf (consume("0x")) base = 16

      if (base == 10)
        local st = scan_number_string
        if (st.contains('.') or st.contains('e') or st.contains('E'))
          if (fn_real) fn_real( this, st->Real64 )
        else
          if (fn_integer) fn_integer( this, st->Int32 )
        endIf
      else
        local n = scan_int64( base )
        if (fn_integer) fn_integer( this, n )
      endIf

      return true

    method scan_comment->String
      if (not consume('#')) return null

      buffer.clear
      if (consume('{'))
        # Multi-line comment
        while (scanner.has_another and not consume("}#")) buffer.print( read )
      else
        # Single-line comment
        while (scanner.has_another and not peek == '\n')
          buffer.print( read )
        endWhile
      endIf
      return buffer->String

    method scan_identifier->String
      local ch = peek
      if (not is_id_start(ch)) return null

      buffer.clear
      buffer.print( read )
      ch = peek
      while (is_id_continuation(ch))
        buffer.print( read )
        ch = peek
      endWhile
      return buffer->String

    method scan_int64( base:Int32 )->Int64
      local result : Int64
      while (peek.is_number(base))
        result = result * base + read.to_number
      endWhile
      return result

endClass

